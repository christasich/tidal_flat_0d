{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import feather\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing as mp\n",
    "import itertools\n",
    "import inspect\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform == 'linux':\n",
    "    os.chdir('/home/chris/projects/tidal_flat_0d/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file, start, end, dt):\n",
    "    def parser(x):\n",
    "        return pd.datetime.strptime(x, '%d-%b-%Y %H:%M:%S')\n",
    "    df = pd.read_csv(file, parse_dates=[\n",
    "        'datetime'], date_parser=parser, index_col='datetime')\n",
    "    df1 = df[(df.index >= start) & (df.index < end)]\n",
    "    resample_df = df1.resample(dt).first()\n",
    "    return resample_df['pressure'] - np.mean(resample_df['pressure'])\n",
    "\n",
    "def rep_series(df, start, end):\n",
    "    freq = df.index.freq\n",
    "    index = pd.DatetimeIndex(start=start, end=rep_end, freq=freq)\n",
    "    values = np.tile(df.values, rep + 1)[:len(index)]\n",
    "    return pd.Series(data=values, index=index)\n",
    "\n",
    "def make_tides(slr):\n",
    "    global run_length, dt\n",
    "    \n",
    "    Rscript = \"Rscript\"\n",
    "    path = os.path.join(os.getcwd(),'scripts/make_tides.R')\n",
    "    subprocess.run([Rscript, path, str(run_length), str(dt), '%.4f' % slr, os.getcwd()])\n",
    "    \n",
    "    tides = feather.read_dataframe('./data/interim/tides/tides-yr_{0}-dt_{1}-slr_{2}.feather'.format(run_length, int(pd.to_timedelta(dt).total_seconds()/60/60), '%.4f' % slr))\n",
    "    tides = tides.set_index('Datetime')\n",
    "    \n",
    "    return tides\n",
    "\n",
    "def calc_c0(h, dh, z, A, timestamp):\n",
    "    global ssc_by_week\n",
    "    week = timestamp.week\n",
    "    ssc = ssc_by_week.loc[week].values[0]\n",
    "    if (h > z and dh > 0):\n",
    "        return A * ssc\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def calc_c(c0, h, h_min_1, dh, c_min_1, z, ws, dt):\n",
    "    if (h > z and dh > 0):\n",
    "        return (c0 * (h-h_min_1) + c_min_1 * (h - z)) / (2 * h - h_min_1 - z + ws / dt)\n",
    "    elif (h > z and dh < 0):\n",
    "        return (c_min_1 * (h - z)) / (h - z + ws / dt)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def calc_dz(c, ws, rho, dt):\n",
    "    return (ws * c / rho) * dt\n",
    "\n",
    "\n",
    "def calc_z(z_min_1, dz_min_1, dO, dP):\n",
    "    return z_min_1 + dz_min_1 + dO - dP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tide_list(slr_list):\n",
    "    \n",
    "    if isinstance(slr_list, list):\n",
    "        pass\n",
    "    elif isinstance(slr_list, float):\n",
    "        slr_list = [slr_list]\n",
    "        \n",
    "    tides_to_make = []\n",
    "    for rate in slr_list:\n",
    "        file = './data/interim/tides/tides-yr_{0}-dt_{1}-slr_{2}.feather'.format(run_length, int(pd.to_timedelta(dt).total_seconds()/60/60), '%.4f' % rate)\n",
    "        if not os.path.isfile(file):\n",
    "            tides_to_make.append(rate)\n",
    "            \n",
    "    return tides_to_make\n",
    "\n",
    "def run_model_pandas(tides, gs, rho, dP, dO, dM, A, z0, n=None):\n",
    "    global ssc_by_week, num_runs\n",
    "    dt = tides.index[1] - tides.index[0]\n",
    "    dt_sec = dt.total_seconds()\n",
    "    ws = ((gs / 1000) ** 2 * 1650 * 9.8) / 0.018\n",
    "    columns = ['h', 'dh', 'C0', 'C', 'dz', 'z']\n",
    "    index = tides.index\n",
    "    df = pd.DataFrame(index=index, columns=columns)\n",
    "    df[:] = 0\n",
    "    df.loc[:, 'z'][0:2] = z0\n",
    "    df.loc[:, 'h'] = tides.pressure\n",
    "    df.loc[:, 'dh'] = df.loc[:, 'h'].diff() / dt_sec\n",
    "    df.loc[:, 'inundated'] = 0\n",
    "    df.loc[:, 'inundation_depth'] = 0\n",
    "\n",
    "    for t in tqdm(tides.index[1:], \n",
    "                  desc='Run {0} of {1} [PID: {2}]'.format(n, num_runs, os.getpid()), \n",
    "                  total=len(tides.index[1:]), \n",
    "                  unit='steps'):\n",
    "        t_min_1 = t - dt\n",
    "        df.loc[t, 'z'] = calc_z(df.at[t_min_1, 'z'], df.at[t_min_1, 'dz'], 0, 0)\n",
    "        df.loc[t, 'C0'] = calc_c0(df.at[t, 'h'], df.at[t, 'dh'], df.at[t, 'z'], A, t)\n",
    "        df.loc[t, 'C'] = calc_c(df.at[t, 'C0'], df.at[t, 'h'], df.at[t_min_1, 'h'],\n",
    "                                df.at[t, 'dh'], df.at[t_min_1, 'C'], df.at[t, 'z'], ws, dt_sec)\n",
    "        df.loc[t, 'dz'] = calc_dz(df.at[t, 'C'], ws, rho, dt_sec)\n",
    "        if df.at[t, 'h'] - df.at[t, 'z'] >= 0:\n",
    "            df.loc[t, 'inundation_depth'] = df.at[t, 'h'] - df.at[t, 'z']\n",
    "        if df.loc[t, 'C0'] != 0:\n",
    "            df.loc[t, 'inundated'] = 1\n",
    "        \n",
    "    hours_inundated = (np.sum(df['inundated']) * dt).astype('timedelta64[h]').astype(int)\n",
    "    final_elevation = df.iloc[[-1]].z.values[0]\n",
    "        \n",
    "    return df, hours_inundated, final_elevation\n",
    "\n",
    "def run_model_numpy(tides, gs, rho, dP, dO, dM, A, z0, n=None):\n",
    "    global ssc_by_week, num_runs\n",
    "    dt = tides.index[1] - tides.index[0]\n",
    "    dt_sec = dt.total_seconds()\n",
    "    ws = ((gs / 1000) ** 2 * 1650 * 9.8) / 0.018\n",
    "    index = tides.index\n",
    "    \n",
    "    z = np.zeros(len(tides.index))\n",
    "    h = tides.pressure.values\n",
    "    dh = np.insert(np.diff(h) / dt_sec,0,np.nan)\n",
    "    inundated = np.zeros(len(tides.index))\n",
    "    inundation_depth = np.zeros(len(tides.index))\n",
    "    C0 = np.zeros(len(tides.index))\n",
    "    C = np.zeros(len(tides.index))\n",
    "    dz = np.zeros(len(tides.index))\n",
    "    \n",
    "    counter = np.arange(1,len(index))\n",
    "    for t in tqdm(counter, \n",
    "                  desc='Run {0} of {1} [PID: {2}]'.format(n, num_runs, os.getpid()), \n",
    "                  total=len(index[1:]), \n",
    "                  unit='steps'):\n",
    "        z[t] = calc_z(z[t-1], dz[t-1], 0, 0)\n",
    "        C0[t] = calc_c0(h[t], dh[t], z[t], A, index[t])\n",
    "        C[t] = calc_c(C0[t], h[t], h[t-1],\n",
    "                                dh[t], C[t-1], z[t], ws, dt_sec)\n",
    "        dz[t] = calc_dz(C[t], ws, rho, dt_sec)\n",
    "        if h[t] - z[t] >= 0:\n",
    "            inundation_depth[t] = h[t] - z[t]\n",
    "        if C0[t] != 0:\n",
    "            inundated[t] = 1\n",
    "        \n",
    "    hours_inundated = int(np.sum(inundated) * dt_sec / 60)\n",
    "    final_elevation = z[-1]\n",
    "    d = {'h' : h, 'dh' : dh, 'C0' : C0, 'C' : C, 'dz' : dz, 'z' : z, \n",
    "         'inundated' : inundated, 'inundation_depth' : inundation_depth}\n",
    "    df = pd.DataFrame(data=d, index = tides.index)\n",
    "    \n",
    "        \n",
    "    return df, hours_inundated, final_elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_combos(run_length, dt, slr, ssc_factor, gs, rho, dP, dO, dM, A, z0):\n",
    "    args = inspect.getfullargspec(make_combos).args\n",
    "    multi_args = []\n",
    "    n = 0\n",
    "    for arg in args:\n",
    "        if isinstance(eval(arg), (list, tuple, np.ndarray)):\n",
    "            multi_args.append(arg)\n",
    "    single_args = list(set(args) - set(multi_args))\n",
    "    dict1 = [{'{0}'.format(j) : eval(j)} for j in single_args]\n",
    "    dict2 = [dict(zip(multi_args, i)) for i in itertools.product(*[eval(x) for x in multi_args])]\n",
    "    for entry2 in dict2:\n",
    "        for entry1 in dict1:\n",
    "            entry2.update(entry1)\n",
    "        entry2.update({'n' : n})\n",
    "        n = n + 1\n",
    "\n",
    "    return dict2\n",
    "\n",
    "def parallel_parser(in_data):\n",
    "    global ssc_by_week\n",
    "\n",
    "    n = in_data['n']\n",
    "    \n",
    "    # make tides\n",
    "    run_length = in_data['run_length']\n",
    "    dt = in_data['dt']\n",
    "    slr = in_data['slr']\n",
    "    \n",
    "    tides = feather.read_dataframe(\n",
    "        './data/interim/tides/tides-yr_{0}-dt_{1}-slr_{2}.feather'.format(run_length, \n",
    "                                                                          int(pd.to_timedelta(dt).total_seconds()/60/60), \n",
    "                                                                          '%.4f' % slr))\n",
    "    tides = tides.set_index('Datetime')\n",
    "    \n",
    "    # Load weeksly ssc\n",
    "    ssc_factor = in_data['ssc_factor']\n",
    "    \n",
    "    ssc_file = './data/processed/ssc_by_week.csv'\n",
    "    ssc_by_week = pd.read_csv(ssc_file, index_col=0) * ssc_factor\n",
    "    \n",
    "    # run model\n",
    "    \n",
    "    gs = in_data['gs']\n",
    "    rho = in_data['rho']\n",
    "    dP = in_data['dP']\n",
    "    dO = in_data['dO']\n",
    "    dM = in_data['dM']\n",
    "    A = in_data['A']\n",
    "    z0 = in_data['z0']\n",
    "    \n",
    "    run_model_numpy(tides, gs, rho, dP, dO, dM, A, z0, n=n)\n",
    "    \n",
    "    out_name = 'yr_{0}-slr_{1}-gs_{2}-rho_{3}-sscfactor_{4}-dP_{5}-dM_{6}-A_{7}-z0_{8}.feather'.format(run_length, slr, gs, rho, ssc_factor, dP, dM, A, z0)\n",
    "    feather.write_dataframe(df.reset_index(), './data/interim/results/{0}'.format(out_name))\n",
    "\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parallel = True\n",
    "run_length = 100\n",
    "dt = '1 hour'\n",
    "slr = 0.002\n",
    "ssc_factor = 1\n",
    "gs = 0.035\n",
    "rho = 1400\n",
    "dP = 0\n",
    "dO = 0\n",
    "dM = 0.003\n",
    "A = 0.7\n",
    "z0 = 0\n",
    "\n",
    "if parallel == True:\n",
    "    poolsize = 30\n",
    "    chunksize = 1\n",
    "    slr = np.round(np.arange(0, 0.0325, 0.0025), 4)\n",
    "    ssc_factor = np.round(np.arange(0.25, 3.25, 0.25), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tides_to_make = make_tide_list(slr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tidal curves already constructed!\n"
     ]
    }
   ],
   "source": [
    "if parallel == True:\n",
    "    \n",
    "    model_runs = make_combos(run_length, dt, slr, ssc_factor, gs, rho, dP, dO, dM, A, z0)\n",
    "    num_runs = len(model_runs)\n",
    "            \n",
    "    if len(tides_to_make) == 0:\n",
    "        print('All tidal curves already constructed!')\n",
    "    else:\n",
    "        print('Making {0} tidal curves.'.format(len(tides_to_make)))\n",
    "        with mp.Pool(poolsize) as pool:\n",
    "            for new_tide in tqdm(pool.imap_unordered(make_tides, tides_to_make),\n",
    "                      total=len(tides_to_make), \n",
    "                      unit='tidal curves'):\n",
    "                pass\n",
    "    \n",
    "    with mp.Pool(poolsize) as pool:\n",
    "        for result in pool.imap_unordered(parallel_parser, model_runs, chunksize=chunksize):\n",
    "            pass\n",
    "        \n",
    "else:\n",
    "    tides = make_tides(slr)\n",
    "    ssc_file = './data/processed/ssc_by_week.csv'\n",
    "    ssc_by_week = pd.read_csv(ssc_file, index_col=0) * ssc_factor\n",
    "    num_runs = 1\n",
    "\n",
    "    df, hours_inundated, final_elevation = run_model_numpy(tides, gs, rho, dP, dO, dM, A, z0, n=1)\n",
    "    out_name = 'yr_{0}-slr_{1}-gs_{2}-rho_{3}-sscfactor_{4}-dP_{5}-dM_{6}-A_{7}-z0_{8}.feather'.format(run_length, slr, gs, rho, ssc_factor, dP, dM, A, z0)\n",
    "    feather.write_dataframe(df.reset_index(), './data/interim/results/{0}'.format(out_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
