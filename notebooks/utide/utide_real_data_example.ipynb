{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T20:05:14.734238Z",
     "iopub.status.busy": "2022-01-02T20:05:14.732303Z",
     "iopub.status.idle": "2022-01-02T20:05:16.096548Z",
     "shell.execute_reply": "2022-01-02T20:05:16.095483Z",
     "shell.execute_reply.started": "2022-01-02T20:05:14.733940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.6\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import utide\n",
    "\n",
    "print(utide.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data file to see what structure it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T20:05:20.096365Z",
     "iopub.status.busy": "2022-01-02T20:05:20.095819Z",
     "iopub.status.idle": "2022-01-02T20:05:20.109545Z",
     "shell.execute_reply": "2022-01-02T20:05:20.108721Z",
     "shell.execute_reply.started": "2022-01-02T20:05:20.096298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0 1998  1  1  0.0000     1.200 0\n",
      "      3600 1998  1  1  1.0000     1.430 0\n",
      "      7200 1998  1  1  2.0000     1.730 0\n",
      "     10800 1998  1  1  3.0000     2.030 0\n",
      "     14400 1998  1  1  4.0000     2.380 0\n",
      "     18000 1998  1  1  5.0000     2.540 0\n",
      "     21600 1998  1  1  6.0000     2.460 0\n",
      "     25200 1998  1  1  7.0000     2.270 0\n",
      "     28800 1998  1  1  8.0000     1.980 0\n",
      "     32400 1998  1  1  9.0000     1.670 0\n",
      "     36000 1998  1  1 10.0000     1.550 0\n",
      "     39600 1998  1  1 11.0000     1.630 0\n",
      "     43200 1998  1  1 12.0000     1.810 0\n",
      "     46800 1998  1  1 13.0000     1.980 0\n",
      "     50400 1998  1  1 14.0000     2.010 0\n",
      "     54000 1998  1  1 15.0000     1.980 0\n",
      "     57600 1998  1  1 16.0000     2.130 0\n",
      "     61200 1998  1  1 17.0000     2.280 0\n",
      "     64800 1998  1  1 18.0000     2.330 0\n",
      "     68400 1998  1  1 19.0000     2.280 0\n",
      "     72000 1998  1  1 20.0000     1.930 0\n",
      "     75600 1998  1  1 21.0000     1.650 0\n",
      "     79200 1998  1  1 22.0000     1.380 0\n",
      "     82800 1998  1  1 23.0000     1.080 0\n",
      "     86400 1998  1  2  0.0000     1.110 0\n",
      "     90000 1998  1  2  1.0000     1.230 0\n",
      "     93600 1998  1  2  2.0000     1.430 0\n",
      "     97200 1998  1  2  3.0000     1.730 0\n",
      "    100800 1998  1  2  4.0000     2.110 0\n",
      "    104400 1998  1  2  5.0000     2.380 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('can1998.dtf') as f:\n",
    "    lines = f.readlines()\n",
    "print(''.join(lines[:30]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the fields are seconds, year, month, day, hour, elevation, flag.  We need a date parser function to combine the date and time fields into a single value to be used as the datetime index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T20:05:29.733136Z",
     "iopub.status.busy": "2022-01-02T20:05:29.732596Z",
     "iopub.status.idle": "2022-01-02T20:05:29.789680Z",
     "shell.execute_reply": "2022-01-02T20:05:29.788697Z",
     "shell.execute_reply.started": "2022-01-02T20:05:29.733074Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/lib/python3.10/site-packages/pandas/io/parsers/base_parser.py:1055: FutureWarning: \n",
      "        Use pd.to_datetime instead.\n",
      "\n",
      "  return generic_parser(date_parser, *date_cols)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elev</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1998-01-01 00:00:00</th>\n",
       "      <td>1.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-01 01:00:00</th>\n",
       "      <td>1.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-01 02:00:00</th>\n",
       "      <td>1.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-01 03:00:00</th>\n",
       "      <td>2.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-01 04:00:00</th>\n",
       "      <td>2.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-01 05:00:00</th>\n",
       "      <td>2.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     elev  flag\n",
       "datetime                       \n",
       "1998-01-01 00:00:00  1.20     0\n",
       "1998-01-01 01:00:00  1.43     0\n",
       "1998-01-01 02:00:00  1.73     0\n",
       "1998-01-01 03:00:00  2.03     0\n",
       "1998-01-01 04:00:00  2.38     0\n",
       "1998-01-01 05:00:00  2.54     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def date_parser(year, month, day, hour):\n",
    "    year, month, day, hour = map(int, (year, month, day, hour))\n",
    "    return datetime.datetime(year, month, day, hour)\n",
    "\n",
    "# Names of the columns that will be used to make a \"datetime\" column:\n",
    "parse_dates = dict(datetime=['year', 'month', 'day','hour'])\n",
    "\n",
    "# Names of the original columns in the file, including only\n",
    "# the ones we will use; we are skipping the first, which appears\n",
    "# to be seconds from the beginning.\n",
    "names = ['year', 'month', 'day', 'hour', 'elev', 'flag']\n",
    "\n",
    "obs = pd.read_table('can1998.dtf',\n",
    "                    names=names,\n",
    "                    skipinitialspace=True,\n",
    "                    delim_whitespace=True,\n",
    "                    index_col='datetime',\n",
    "                    usecols=range(1, 7),\n",
    "                    na_values='9.990',\n",
    "                    parse_dates=parse_dates,\n",
    "                    date_parser=date_parser,\n",
    "                   )\n",
    "obs.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there are no elevations marked bad via special value, which should be `nan` after reading the file, the flag value of 2 indicates the values are unreliable, so we will mark them with `nan`, calculate the deviations of the elevations from their mean (stored in a new column called \"anomaly\"), and then interpolate to fill in the `nan` values in the anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T20:05:42.732678Z",
     "iopub.status.busy": "2022-01-02T20:05:42.732169Z",
     "iopub.status.idle": "2022-01-02T20:05:42.755378Z",
     "shell.execute_reply": "2022-01-02T20:05:42.754123Z",
     "shell.execute_reply.started": "2022-01-02T20:05:42.732620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 points were flagged \"bad\" and interpolated\n",
      "212 points were flagged \"corrected\" and left unchanged\n"
     ]
    }
   ],
   "source": [
    "bad = obs['flag'] == 2\n",
    "corrected = obs['flag'] == 1\n",
    "\n",
    "obs.loc[bad, 'elev'] = np.nan\n",
    "obs['anomaly'] = obs['elev'] - obs['elev'].mean()\n",
    "obs['anomaly'] = obs['anomaly'].interpolate()\n",
    "print('{} points were flagged \"bad\" and interpolated'.format(bad.sum()))\n",
    "print('{} points were flagged \"corrected\" and left unchanged'.format(corrected.sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utide package works with ordinary numpy arrays, not with Pandas Series or Dataframes, so we need to make a `time` variable in floating point days since a given epoch, and use the `values` attribute of the elevation anomaly (a Pandas Series) to extract the underlying numpy ndarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T20:06:00.683436Z",
     "iopub.status.busy": "2022-01-02T20:06:00.682660Z",
     "iopub.status.idle": "2022-01-02T20:06:00.704084Z",
     "shell.execute_reply": "2022-01-02T20:06:00.702755Z",
     "shell.execute_reply.started": "2022-01-02T20:06:00.683360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.datetime(1998, 1, 1, 0, 0),\n",
       "       datetime.datetime(1998, 1, 1, 1, 0),\n",
       "       datetime.datetime(1998, 1, 1, 2, 0), ...,\n",
       "       datetime.datetime(1998, 12, 31, 21, 0),\n",
       "       datetime.datetime(1998, 12, 31, 22, 0),\n",
       "       datetime.datetime(1998, 12, 31, 23, 0)], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.index.to_pydatetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = mdates.date2num(obs.index.to_pydatetime())\n",
    "\n",
    "coef = utide.solve(time, obs['anomaly'].values,\n",
    "                   lat=-25,\n",
    "                   method='ols',\n",
    "                   conf_int='MC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amplitudes and phases from the fit are now in the `coef` data structure (a Bunch), which can be used directly in the `reconstruct` function to generate a hindcast or forecast of the tides at the times specified in the `time` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coef.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tide = utide.reconstruct(time, coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from the reconstruction is also a Bunch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tide.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = obs.index.values  # dtype is '<M8[ns]' (numpy datetime64)\n",
    "# It is more efficient to supply the time directly as matplotlib\n",
    "# datenum floats:\n",
    "t = tide.t_mpl\n",
    "\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, sharey=True, sharex=True)\n",
    "\n",
    "ax0.plot(t, obs.anomaly, label=u'Observations', color='C0')\n",
    "ax1.plot(t, tide.h, label=u'Tide Fit', color='C1')\n",
    "ax2.plot(t, obs.anomaly - tide.h, label=u'Residual', color='C2')\n",
    "ax2.xaxis_date()\n",
    "fig.legend(ncol=3, loc='upper center')\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
